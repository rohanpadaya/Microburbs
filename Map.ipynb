{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bdb5326-3eb4-47ef-b685-7815761e9979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.11/site-packages (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f67dc-034f-4772-87e0-bc91eb55c2b8",
   "metadata": {},
   "source": [
    "## Trying to modify the lines using this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83948036-4698-40fd-8719-88b628c7cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Load the image\n",
    "image_path = \"/Users/rohanpadaya/Downloads/Screenshot 2024-08-02 at 2.36.22 pm.png\"\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Example of modifying the line thickness or color\n",
    "# Coordinates here are hypothetical as an example; for real use, you'd need exact line coordinates\n",
    "# Modify the existing lines (for demonstration, using a set of random lines)\n",
    "# Coordinates must be adapted based on the original image's content\n",
    "\n",
    "# Draw thicker, semi-transparent lines (if coordinates are known)\n",
    "draw.line((100, 100, 300, 300), fill=(255, 0, 0, 128), width=5)\n",
    "draw.line((100, 300, 300, 100), fill=(0, 255, 0, 128), width=5)\n",
    "draw.line((150, 150, 350, 350), fill=(0, 0, 255, 128), width=5)\n",
    "\n",
    "# Save the modified image\n",
    "modified_image_path = \"/Users/rohanpadaya/Downloads/modified_image.png\"\n",
    "img.save(modified_image_path)\n",
    "\n",
    "# Display the modified image (optional)\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a08796-a41a-41df-a2c1-8713d8e3b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.11/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab957ee-6bba-47aa-848f-9d3782b7013a",
   "metadata": {},
   "source": [
    "## Enhancing Visibility by Lightening Blue Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5afcd6f5-628d-4657-99fa-039ac479816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image_path = \"/Users/rohanpadaya/Downloads/Screenshot 2024-08-02 at 2.36.22 pm.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to HSV color space\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the range of blue color in HSV\n",
    "lower_blue = np.array([100, 150, 0])\n",
    "upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "# Create a mask for the blue color\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "# Inpaint the image using the mask\n",
    "inpainted_image = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "# Convert the inpainted image back to RGB for displaying with PIL\n",
    "inpainted_image_rgb = cv2.cvtColor(inpainted_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Save the resulting image using PIL\n",
    "result_image_path = \"/Users/rohanpadaya/Downloads/modified_image.png\"\n",
    "result_image = Image.fromarray(inpainted_image_rgb)\n",
    "result_image.save(result_image_path)\n",
    "\n",
    "# Display the modified image (optional)\n",
    "result_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed19959-9afc-4365-aefd-e79afd74c4b0",
   "metadata": {},
   "source": [
    "## Keeping just the nodes and the edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25004b04-b91a-4a6f-9c3b-dbeddfa86a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image_path = \"/Users/rohanpadaya/Downloads/Screenshot 2024-08-02 at 2.36.22 pm.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to HSV color space\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the range of blue color in HSV\n",
    "lower_blue = np.array([100, 150, 0])\n",
    "upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "# Create a mask for the blue color\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "# Create an inverse mask to keep only non-blue areas\n",
    "inverse_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Convert the entire image to white\n",
    "white_background = np.ones_like(image) * 255\n",
    "\n",
    "# Use the mask to retain the blue lines and set the rest to white\n",
    "result = cv2.bitwise_and(image, image, mask=mask)\n",
    "result = cv2.add(result, cv2.bitwise_and(white_background, white_background, mask=inverse_mask))\n",
    "\n",
    "# Convert the result back to RGB for saving with PIL\n",
    "result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Save the resulting image using PIL\n",
    "result_image_path = \"/Users/rohanpadaya/Downloads/modified_image.png\"\n",
    "result_image = Image.fromarray(result_rgb)\n",
    "result_image.save(result_image_path)\n",
    "\n",
    "# Display the modified image (optional)\n",
    "result_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c22b8-7057-4f9d-b250-70d0c11da185",
   "metadata": {},
   "source": [
    "# Using Graph layout algorithm to improve visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d76b529-caa8-4c8e-afef-7e781e7daf73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "images do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m graph_img \u001b[38;5;241m=\u001b[39m graph_img\u001b[38;5;241m.\u001b[39mresize(original_img\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Blend the images\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m blended \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mblend(original_img, graph_img, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Adjust alpha for blending\u001b[39;00m\n\u001b[1;32m     80\u001b[0m blended\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/rohanpadaya/Downloads/modified_image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m blended\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/PIL/Image.py:3351\u001b[0m, in \u001b[0;36mblend\u001b[0;34m(im1, im2, alpha)\u001b[0m\n\u001b[1;32m   3349\u001b[0m im1\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   3350\u001b[0m im2\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m-> 3351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im1\u001b[38;5;241m.\u001b[39m_new(core\u001b[38;5;241m.\u001b[39mblend(im1\u001b[38;5;241m.\u001b[39mim, im2\u001b[38;5;241m.\u001b[39mim, alpha))\n",
      "\u001b[0;31mValueError\u001b[0m: images do not match"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = \"/Users/rohanpadaya/Downloads/Screenshot 2024-08-02 at 2.36.22 pm.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to HSV color space\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the range of blue color in HSV\n",
    "lower_blue = np.array([100, 150, 0])\n",
    "upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "# Create a mask for the blue color\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "# Find contours in the mask (these correspond to nodes and edges)\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter the contours to find nodes (approximate as circles)\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "for contour in contours:\n",
    "    approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)\n",
    "    if len(approx) > 8:  # This is likely a node (city marker)\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            nodes.append((cx, cy))\n",
    "    else:\n",
    "        edges.append(contour)\n",
    "\n",
    "# Create a graph from the nodes and edges\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for i, (cx, cy) in enumerate(nodes):\n",
    "    G.add_node(i, pos=(cx, cy))\n",
    "\n",
    "# Add edges to the graph\n",
    "for edge in edges:\n",
    "    # Find the closest node to each end of the edge\n",
    "    M = cv2.moments(edge)\n",
    "    if M['m00'] != 0:\n",
    "        ex = int(M['m10'] / M['m00'])\n",
    "        ey = int(M['m01'] / M['m00'])\n",
    "        closest_nodes = sorted(nodes, key=lambda p: np.linalg.norm(np.array(p) - np.array((ex, ey))))[:2]\n",
    "        if len(closest_nodes) == 2:\n",
    "            idx1 = nodes.index(closest_nodes[0])\n",
    "            idx2 = nodes.index(closest_nodes[1])\n",
    "            G.add_edge(idx1, idx2)\n",
    "\n",
    "# Apply a layout algorithm (e.g., spring layout) to rearrange the nodes\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Draw the graph with the new layout\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=3000, font_size=15, font_weight='bold', edge_color='blue')\n",
    "\n",
    "# Save the improved map\n",
    "improved_map_path = \"/Users/rohanpadaya/Downloads/modified_image.png\"\n",
    "plt.savefig(improved_map_path)\n",
    "plt.close()\n",
    "\n",
    "# Load the saved graph image and original image\n",
    "graph_img = Image.open(improved_map_path)\n",
    "original_img = Image.open(image_path)\n",
    "\n",
    "# Resize the graph image to match the original image's size\n",
    "graph_img = graph_img.resize(original_img.size)\n",
    "\n",
    "# Blend the images\n",
    "blended = Image.blend(original_img, graph_img, alpha=0.5)  # Adjust alpha for blending\n",
    "blended.save(\"/Users/rohanpadaya/Downloads/modified_image.png\")\n",
    "blended.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae9a11-4fdc-4206-b95a-bd614d59c4ea",
   "metadata": {},
   "source": [
    "As part of the assessment I tried multiple techniques to improve the visibility, however I was enable to find the most effective approach. \n",
    "* The Initial idea was to try and dim the edges to improve visibility. However, that still did not change the readibility much as the lines were overlapping. \n",
    "* The next attempt was to identify the nodes and edges from the image and redraw the map by avoiding overlaps between the edges and the distance values.Unfortunately, I failed to classify the nodes and edges from the image. I tried to classify using color and contour but was unsuccessful to do so.\n",
    "\n",
    "The solution to this I believe lies in classifying the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
